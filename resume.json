{
  "basics": {
    "name": "Matthew Dantas-McCutcheon",
    "label": "Software Engineer",
    "picture": "",
    "email": "mateusdm88@gmail.com",
    "phone": "(202) 753-4966",
		"summary": "Software engineer, problem-solving generalist. I have a track record of wearing whatever hats need wearing - engaging with customers and POs to make product decisions, scrum mastering to keep my team running smoothly, leading tech efforts, and individually contributing. I find greatest satisfaction in having a large customer impact and finding elegant solutions to hard problems that draw on math and science. Most recently, I'm scratching the latter itch by learning Haskell while solving problems on ProjectEuler.",
    "profiles": [
      {
        "network": "Github",
        "username": "mDantas",
        "url": "https://github.com/mDantas"
      }
    ]
  },
  "work": [
    {
      "company": "Vistaprint",
      "position": "Software Engineer, Vistaprint Data Warehouse",
      "startDate": "2017-10-01",
      "endDate": "Present",
      "summary": "As part of a two person team, I am getting Vistaprint Digital's subscription data from disparate relational sources (~12 products across two billing platforms) into a central data warehouse. My contribution has been co-creating and now refining the target fact and dimension tables as well as the sprocs that populate them. Most of the work is in Azure Data Warehouse. The data will be used to forecast, per-product, KPIs like signups, bookings, cancellations, etc.",
			"highlights": [
				"Normalizing data from relational format to columnar-stored fact/dimension tables (star schema).",
				"Using change-tracking-replication infrastructure to copy data over for processing."
			]
    },
    {
      "company": "Vistaprint",
      "position": "Software Engineer, Local Listings product",
      "website": "www.vistaprint.com/local-listings.aspx",
      "startDate": "2015-04-01",
      "endDate": "2017-10-01",
      "summary": "I worked on Vistaprint's Local Listings product, a tool for small businesses to disseminate their contact information across various platforms so customers can find them. My contributions spanned a Postgres/Express/React/Node stack with a focus on the backend. I was scrum master for my team, participated in core product decisions, became the app's principal contributor, and am on the on-call rotation.",
      "highlights": [
        "Tech led a team of 3 in the migration from one third-party backend service provider to another. In numbers, the effort spanned about 4 months of effort, ~100 Jira tickets covering work across the stack, and affected ~40k existing users (and all our new signups).",
        "Refactored the application database schema (~6 tables, ~6 views) from update-driven to event-driven so we could better measure customer impact.",
        "From ideation to implementation, introduced a method to measure customer impact: as a recurring job, search google for our customers' businesses and check the search results for fuzzy matches of customer-identifying information. This involved using Google's custom search engine API, parsing the JSON, and using the Levenshtein algorithm to find closest matches to specified customer business parameters (e.g. name and zip). I've pasted a link to a small, fun open source contribution that resulted from this work.",
        "Wep-API-related engineering: writing request.js-based clients, processing JSON, ad-hoc analysis of 3rd party partner data (curl + jq and then dumping that data to postgres to perform queries across our data & partner data). This was not an isolated project but rather a significant part of the bread-and-butter of working on the Local Listings app.",
        "Internationalization (using react-intl)",
        "Expanding the application's unit test footprint."
      ]
    },
    {
      "company": "Vistaprint",
      "position": "Software Engineer, Pagemodo product",
      "website": "http://www.pagemodo.com",
      "startDate": "2014-06-01",
      "endDate": "2015-04-01",
      "summary": "Worked on the Pagemodo product - a Rails app with postgres backend hosted on Heroku with some Backbone & React on the frontend. My contributions were primarily as an individual feature contributor. My greatest isolated contribution was this experience for Social Media Marketing World 2015: https://www.pagemodo.com/smmw15. This was a vertical slice of work on the stack - wiring up models and controllers, the twitter integration, setting up a backbone app for the image carousel, etc. The \"designer\" that pops open if you click on a design already existed, I just ported it into this experience. I also did not do the html/css on the linked page. My other main contributions during this time included work on pagemodo's teams feature and some work with Apache SOLR to improve our content recommendation.",
      "highlights": [
        "A Twitter-post integrated Backbone SPA for Social Media Marketing World 2015 (https://www.pagemodo.com/smmw15). This was a thin vertical slice of work, adding tables/models, controller, views, and a Backbone app. The post designer to which I integrated the Twitter-posting experience already existed as a core feature of the Pagemodo product.",
        "Pagemodo teams feature - writing Rails controllers and a Backbone spa FIXME - Marionetter",
        "Apache SOLR - FIXME",
        "Sundry bug fixes and small feature tickets."
      ]
    },
    {
      "company": "Dell @ Executive Office of the President",
      "position": "Rails developer - Max.gov",
      "website": "https://max.gov",
      "startDate": "2013-04-01",
      "endDate": "2014-06-01",
      "summary": "Worked on max.gov, a tool to collect human-entered data across agencies (e.g. to compile the federal budget). My main contribution was a fault-tolerant script to migrate tree-subsets of records (order of magnitude, ~100k) from a legacy database with Latin1 encoding to a new databases with UTF8 encoding. A script existed at the time but it was shown to result in data corruption (it did an inconsistently shallow/deep copy) and also could take up to a day or two to run. The new script would run in minutes to hours. The end result could be considered an ETL implemented in Ruby and Rails and was used to migrate all existing federal agencies' data to the new database.",
      "highlights": [
        "Used binary search to robustly insert a 'haystack' of good data while collecting the 'needles' of bad data (usually records whose Latin1 to UTF8 translation overflowed the column size)",
        "Wrote logic to traverse the application schema (~10 tables), select the entire source tree of data into memory, use Ruby to dynamically create the bulk insertion statements to insert the data into the target database in-order so as to respect relational integrity."
      ]
    },
    {
      "company": "Lockheed Martin",
      "position": "Systems Engineer Asc",
      "startDate": "2011-04-01",
      "endDate": "2014-06-01",
      "summary": "Sundry assignments, most relevant being as a Rails dev, 10/11 â€“ 04/12, and then writing JasperReports SQL queries for a different project.",
      "highlights": [
        "Developed (as sole and full-stack developer learning on the fly) a web application for placing and reviewing procurement orders following a role-based approval workflow. I worked on a CentOS machine and Ruby on Rails, role-based authorization, authentication, LDAP, cron jobs, SMTP mailer, deterministic finite automata (to implement the state machine for order workflow), CSS3, MySQL",
				"Tested and corrected system-generated Jasper reports",
				"Scripted a domain-specific-language in Python to speed up generation of Jasper reports"
      ]
    },
		{
			"company": "Booz Allen Hamilton",
      "position": "Intern",
			"startDate": "2010-06-01",
			"endDate": "2010-08-01",
			"summary": "BAH's cybersecurity summer internship program",
			"highlights": [
				"Developed software to gather open-source intelligence as part of a 3 person team",
				"Presented to fellow interns and employees on the project's outcome",
				"Skills: web scraping, web crawling, Python"
			]
		},
		{
			"company": "Institute for Physical Sciences and Technology, University of Maryland College Park",
      "position": "Undergraduate Researcher",
			"startDate": "2006-06-01",
			"endDate": "2009-10-01",
			"webiste": "http://www.ipst.umd.edu/undergraduate/",
			"summary": "Built a numerical model of a time-of-flight ion mass spectrometer.",
			"highlights": [
				"Independently designed and implemented the simulation of an instrument measuring solar wind composition.",
				"Designed and prototyped a genetic algorithm to deduce solar wind composition from instrument output spectra",
				"Authored 70 pages documenting design, development, and usage of the simulator",
				"Skills: numerical model design, Monte Carlo simulation, genetic algorithms, parameterization of large data sets, automation of data collection and analysis, C, bat scripts, Microsoft VBA, SRIM, technical writing, Java"
			]
		}
  ],
  "education": [
    {
      "institution": "University of Maryland, College Park",
      "area": "Mathematics",
      "studyType": "Bachelor of Science",
      "startDate": "2006-09-01",
      "endDate": "2011-05-01",
      "gpa": "3.6",
      "courses": [
        "Real analysis",
        "Quantum physics",
        "Linear algebra",
        "Combinatorics",
        "Cryptology",
        "Computational methods"
      ]
    },
    {
      "institution": "University of Maryland, College Park",
      "area": "Computer Science",
      "studyType": "Bachelor of Science",
      "startDate": "2006-09-01",
      "endDate": "2011-05-01",
      "gpa": "3.6",
      "courses": [
        "Machine Learning",
        "Algorithms",
        "Systems Architecture"
      ]
    }
  ],
  "skills": [
    {
      "name": "Web Development",
      "level": "Experienced",
      "keywords": [
        "Express",
        "Node",
        "React",
        "Rails",
        "Templating",
        "Creating web APIs",
        "ORM",
        "il8n"
      ]
    },
    {
      "name": "Relational databases",
      "level": "Experienced",
      "keywords": [
        "Postgres",
        "DB2",
        "Sql server",
        "Common table expressions",
        "Stored procedures",
        "Views",
        "Indexes",
        "Query inspection/design/optimization"
      ]
    },
    {
      "name": "Software Development Lifecycle",
      "level": "Experienced",
      "keywords": [
        "On-call rotation",
        "Scrum",
        "JIRA",
        "git",
        "scrum master",
        "distributed teams"
      ]
    },
    {
      "name": "Ops/Cloud",
      "level": "Experienced",
      "keywords": [
        "Heroku",
        "Logentries",
        "NewRelic"
      ]
    },
    {
      "name": "Testing",
      "level": "Experienced",
      "keywords": [
        "Stubs",
        "Spies",
        "Mocks",
        "Mocha"
      ]
    },
    { "name": "Data warehousing",
      "level": "Some experience",
      "keywords": [
        "Microsoft Parallel Data Warehouse",
        "Azure Data Warehouse",
        "Columnar data storage",
        "Star schema",
        "ETL"
      ]
    },
    {
      "name": "Ops/Infrastructure",
      "level": "Some experience",
      "keywords": [
        "Docker",
        "Bamboo"
      ]
    },
    {
      "name": "Functional Languages",
      "level": "Some experience",
      "keywords": [
        "Haskell"
      ]
    }
  ],
  "languages": [
    {
      "language": "Portuguese",
      "fluency": "Native fluency"
    },
    {
      "language": "French",
      "fluency": "Professional proficiency"
    }
  ],
  "interests": [
    {
      "name": "Cycling",
      "keywords": [
        "Crits",
        "Cyclocross"
      ]
    },
    {
      "name": "Art",
      "keywords": [
        "Theatre",
        "20th century literature",
        "Magritte"
      ]
    },
    {
      "name": "Recreational Math",
      "keywords": [
        "ProjectEuler"
      ]
    }
  ]
}
