{
  "basics": {
    "name": "Matthew Dantas-McCutcheon",
    "label": "Software Engineer",
    "picture": "",
    "email": "mateusdm88@gmail.com",
    "phone": "(202) 753-4966",
    "summary": "I like solving inherently hard problems with large impact. I take special pleasure when solving these calls on and expands my knowledge of math and computer science.",
    "profiles": [
      {
        "network": "Github",
        "username": "mDantas",
        "url": "https://github.com/mDantas"
      }
    ]
  },
  "work": [
    {
      "company": "Vistaprint",
      "position": "Software Engineer, Vistaprint Data Warehouse",
      "startDate": "2017-10-01",
      "endDate": "Present",
      "summary": "As part of a two person team, I am working on getting our bookings/subscription data from disparate relational sources (~12 products across two billing platforms) into the company's centralized, columnar-storage data warehouse and optimizing the shape of the data to BI's queries. This has involved moving source data over as-is, designing a pair of fact and dimension tables to fit the data into, and writing sprocs to normalize the relational data into columnar fact/dimension form. I remain on the on-call rotation for Vistaprint Digital's marketing products."
    },
    {
      "company": "Vistaprint",
      "position": "Software Engineer, Local Listings product",
      "website": "www.vistaprint.com/local-listings.aspx",
      "startDate": "2015-04-01",
      "endDate": "2017-10-01",
      "summary": "I worked on Vistaprint's Local Listings product, a tool for small businesses to disseminate their contact information across various platforms so customers can find them. My contributions spanned a Postgres/Express/React/Node stack with a focus on the backend. I was scrum master for my team, participated in core product decisions, became the app's principal contributor, and am on the on-call rotation.",
      "highlights": [
        "Tech led a team of 3 in the migration from one third-party backend service provider to another. In numbers, the effort spanned about 4 months of effort, ~100 Jira tickets covering work across the stack, and affected ~40k existing users (and all our new signups).",
        "Refactored the application database schema (~6 tables, ~6 views) from update-driven to event-driven so we could better measure customer impact.",
        "From ideation to implementation, introduced a method to measure customer impact: as a recurring job, search google for our customers' businesses and check the search results for fuzzy matches of customer-identifying information. This involved using Google's custom search engine API, parsing the JSON, and using the Levenshtein algorithm to find closest matches to specified customer business parameters (e.g. name and zip). I've pasted a link to a small, fun open source contribution that resulted from this work.",
        "Wep-API-related engineering: writing request.js-based clients, processing JSON, ad-hoc analysis of 3rd party partner data (curl + jq and then dumping that data to postgres to perform queries across our data & partner data). This was not an isolated project but rather a significant part of the bread-and-butter of working on the Local Listings app.",
        "Internationalization (using react-intl)",
        "Expanding the application's unit test footprint."
      ]
    },
    {
      "company": "Vistaprint",
      "position": "Software Engineer, Pagemodo product",
      "website": "http://www.pagemodo.com",
      "startDate": "2014-06-01",
      "endDate": "2015-04-01",
      "summary": "Worked on the Pagemodo product - a Rails app with postgres backend hosted on Heroku with some Backbone & React on the frontend. My contributions were primarily as an individual feature contributor. My greatest isolated contribution was this experience for Social Media Marketing World 2015: https://www.pagemodo.com/smmw15. This was a vertical slice of work on the stack - wiring up models and controllers, the twitter integration, setting up a backbone app for the image carousel, etc. The \"designer\" that pops open if you click on a design already existed, I just ported it into this experience. I also did not do the html/css on the linked page. My other main contributions during this time included work on pagemodo's teams feature and some work with Apache SOLR to improve our content recommendation.",
      "highlights": [
        "A Twitter-post integrated Backbone SPA for Social Media Marketing World 2015 (https://www.pagemodo.com/smmw15). This was a thin vertical slice of work, adding tables/models, controller, views, and a Backbone app. The post designer to which I integrated the Twitter-posting experience already existed as a core feature of the Pagemodo product.",
        "Pagemodo teams feature - writing Rails controllers and a Backbone spa FIXME - Marionetter",
        "Apache SOLR - FIXME",
        "Sundry bug fixes and small feature tickets."
      ]
    },
    {
      "company": "Dell @ Executive Office of the President",
      "position": "Rails developer - Max.gov",
      "website": "https://max.gov",
      "startDate": "2013-04-01",
      "endDate": "2014-06-01",
      "summary": "Worked on max.gov, a tool to collect human-entered data across agencies (e.g. to compile the federal budget). My main contribution was a fault-tolerant script to migrate tree-subsets of records (order of magnitude, ~100k) from a legacy database with Latin1 encoding to a new databases with UTF8 encoding. A script existed at the time but it was shown to result in data corruption (it did an inconsistently shallow/deep copy) and also could take up to a day or two to run. The new script would run in minutes to hours. The end result could be considered an ETL implemented in Ruby and Rails and was used to migrate all existing federal agencies' data to the new database.",
      "highlights": [
        "Used binary search to robustly insert a 'haystack' of good data while collecting the 'needles' of bad data (usually records whose Latin1 to UTF8 translation overflowed the column size)",
        "Wrote logic to traverse the application schema (~10 tables), select the entire source tree of data into memory, use Ruby to dynamically create the bulk insertion statements to insert the data into the target database in-order so as to respect relational integrity."
      ]
    },
    {
      "company": "Lockheed Martin",
      "position": "Systems Engineer Asc",
      "startDate": "2013-04-01",
      "endDate": "2014-06-01",
      "summary": "Sundry assignments, most relevant being as a Rails dev, 10/11 â€“ 04/12",
      "highlights": [
        "Developed (as sole and full-stack developer learning on the fly) a web application for placing and reviewing procurement orders following a role-based approval workflow",
        " Linux OS, Ruby, Ruby on Rails, role-based authorization, authentication, LDAP, cron jobs, SMTP mailer, deterministic finite automata (to implement the state machine for order workflow), CSS3, MySQL"
      ]
    }
  ],
  "education": [
    {
      "institution": "University of Maryland, College Park",
      "area": "Mathematics",
      "studyType": "Bachelor of Science",
      "startDate": "2006-09-01",
      "endDate": "2011-05-01",
      "gpa": "3.6",
      "courses": [
        "Real analysis",
        "Quantum physics",
        "Linear algebra",
        "Combinatorics",
        "Cryptology",
        "Computational methods"
      ]
    },
    {
      "institution": "University of Maryland, College Park",
      "area": "Computer Science",
      "studyType": "Bachelor of Science",
      "startDate": "2006-09-01",
      "endDate": "2011-05-01",
      "gpa": "3.6",
      "courses": [
        "Machine Learning",
        "Algorithms",
        "Systems Architecture"
      ]
    }
  ],
  "skills": [
    {
      "name": "Web Development",
      "level": "Experienced",
      "keywords": [
        "Express",
        "Node",
        "React",
        "Rails",
        "Templating",
        "Creating web APIs",
        "ORM",
        "il8n"
      ]
    },
    {
      "name": "Relational databases",
      "level": "Experienced",
      "keywords": [
        "Postgres",
        "DB2",
        "Sql server",
        "Common table expressions",
        "Stored procedures",
        "Views",
        "Indexes",
        "Query inspection/design/optimization"
      ]
    },
    {
      "name": "Software Development Lifecycle",
      "level": "Experienced",
      "keywords": [
        "On-call rotation",
        "Scrum",
        "JIRA",
        "git",
        "scrum master",
        "distributed teams"
      ]
    },
    {
      "name": "Ops/Cloud",
      "level": "Experienced",
      "keywords": [
        "Heroku",
        "Logentries",
        "NewRelic"
      ]
    },
    {
      "name": "Testing",
      "level": "Experienced",
      "keywords": [
        "Stubs",
        "Spies",
        "Mocks",
        "Mocha"
      ]
    },
    { "name": "Data warehousing",
      "level": "Some experience",
      "keywords": [
        "Microsoft Parallel Data Warehouse",
        "Azure Data Warehouse",
        "Columnar data storage",
        "Star schema",
        "ETL"
      ]
    },
    {
      "name": "Ops/Infrastructure",
      "level": "Some experience",
      "keywords": [
        "Docker",
        "Bamboo"
      ]
    },
    {
      "name": "Functional Languages",
      "level": "Some experience",
      "keywords": [
        "Haskell"
      ]
    }
  ],
  "languages": [
    {
      "language": "Portuguese",
      "fluency": "Native fluency"
    },
    {
      "language": "French",
      "fluency": "Professional proficiency"
    }
  ],
  "interests": [
    {
      "name": "Cycling",
      "keywords": [
        "Crits",
        "Cyclocross"
      ]
    },
    {
      "name": "Art",
      "keywords": [
        "Theatre",
        "20th century literature",
        "Magritte"
      ]
    },
    {
      "name": "Recreational Math",
      "keywords": [
        "ProjectEuler"
      ]
    }
  ]
}
